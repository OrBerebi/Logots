{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7612989-0985-4188-ab84-99c920e5bc17",
   "metadata": {},
   "source": [
    "# Pipeline Code Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41491e6-845c-430c-be3e-f16724c568ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 0: CONFIGURE DISPLAY ---\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Remove limits on how many columns and rows are shown\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None)     # Show all rows\n",
    "pd.set_option('display.max_colwidth', None) # Don't truncate content inside cells\n",
    "pd.set_option('display.width', None)        # Auto-detect screen width\n",
    "\n",
    "print(\"✅ Pandas display limits removed. Be careful printing huge dataframes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5c41a-ee1e-478c-824b-c5d97c9c9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 1: SETUP ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "# Import your specific file. \n",
    "# Ensure transformation_mart_pipeline.py is in the same folder as this notebook.\n",
    "import transformation_mart_pipeline as robot_code\n",
    "\n",
    "# Check if it loaded correctly by printing the version or a known variable\n",
    "print(f\"✅ Loaded pipeline. VISUAL_CONF_THR is set to: {robot_code.VISUAL_CONF_THR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26c51d-12bb-458d-a155-6c49939b0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 2: DATA LOADING ---\n",
    "# Load your local CSVs (or generate synthetic data if you don't have them yet)\n",
    "\n",
    "try:\n",
    "    audio_df = pd.read_csv('stg_audio_data.csv')\n",
    "    imu_df = pd.read_csv('stg_imu_data.csv')\n",
    "    visual_df = pd.read_csv('stg_visual_data.csv')\n",
    "    motor_df = pd.read_csv('stg_motor_data.csv')\n",
    "    print(\"✅ Real Data Loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Files not found. You need the CSV files in this folder to run the pipeline.\")\n",
    "    # If you need the synthetic data generator from the previous answer, \n",
    "    # you can paste just that function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c373ae-b0d1-41a2-b0cd-2298c27eb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 3: TRANSFORM (SAFE MODE) ---\n",
    "\n",
    "# 1. AUDIO (Will auto-clean memory after running)\n",
    "print(\"Processing Audio...\")\n",
    "t_audio = robot_code.transform_audio(audio_df)\n",
    "\n",
    "# 2. IMU (Lightweight, safe to run)\n",
    "print(\"Processing IMU...\")\n",
    "t_imu = robot_code.transform_imu(imu_df)\n",
    "\n",
    "# 3. VISUAL (Heavy, run last)\n",
    "print(\"Processing Visual...\")\n",
    "# Tip: Use 'yolov8n.pt' (nano) instead of 'medium' if you still crash\n",
    "t_visual = robot_code.transform_visual(visual_df, device='cpu') \n",
    "\n",
    "# 4. MOTOR\n",
    "print(\"Processing Motor...\")\n",
    "t_motor = robot_code.transform_motor(motor_df)\n",
    "\n",
    "print(\"✅ All transformations complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5c0ff-d38a-4663-84b4-3d278a9a8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 4: INSPECT INTERMEDIATES ---\n",
    "\n",
    "# display(t_visual) \n",
    "# display(t_imu)\n",
    "display(t_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8382c-8c1c-4441-96e5-710aef681df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 5: MART GENERATION ---\n",
    "\n",
    "mart_df = robot_code.build_mrt_experiences(\n",
    "    t_audio, \n",
    "    t_imu, \n",
    "    t_visual, \n",
    "    t_motor, \n",
    "    N_FRAMES=12\n",
    ")\n",
    "\n",
    "print(f\"✅ Mart Built. Total Experience Rows: {len(mart_df)}\")\n",
    "display(mart_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e888d6d-f0ab-43ef-87cf-e5e823611683",
   "metadata": {},
   "source": [
    "# Pipeline Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b0fab-1295-40fc-acf2-4f0bd0b7e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL: SPECTROGRAM + DETECTION VISUALIZER ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import transformation_mart_pipeline as robot_code\n",
    "\n",
    "# 1. Load Raw Data\n",
    "print(\"Loading data...\")\n",
    "df_audio = pd.read_csv('stg_audio_data.csv')\n",
    "\n",
    "# 2. Parse Audio Samples\n",
    "print(\"Parsing audio samples...\")\n",
    "all_samples = []\n",
    "frame_ids = []\n",
    "\n",
    "def parse_samples(val):\n",
    "    if isinstance(val, str):\n",
    "        try: return ast.literal_eval(val)\n",
    "        except: return []\n",
    "    return val if isinstance(val, list) else []\n",
    "\n",
    "for idx, row in df_audio.iterrows():\n",
    "    s = parse_samples(row['audio_samples'])\n",
    "    if s:\n",
    "        all_samples.extend(s)\n",
    "        frame_ids.append(row['frame_id'])\n",
    "\n",
    "audio_stream = np.array(all_samples)\n",
    "\n",
    "# 3. Run the Pipeline\n",
    "print(\"Running detection pipeline...\")\n",
    "# This will now use the CPU and should NOT crash\n",
    "t_audio = robot_code.transform_audio(df_audio)\n",
    "\n",
    "# 4. PLOTTING\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "# --- TOP PLOT: SPECTROGRAM ---\n",
    "if len(audio_stream) > 0:\n",
    "    Pxx, freqs, bins, im = ax1.specgram(\n",
    "        audio_stream, \n",
    "        NFFT=1024, \n",
    "        Fs=16000,   \n",
    "        noverlap=512, \n",
    "        cmap='magma'\n",
    "    )\n",
    "    # Align visual extent to frame IDs\n",
    "    if frame_ids:\n",
    "        im.set_extent([min(frame_ids), max(frame_ids), 0, 8000]) \n",
    "    \n",
    "    ax1.set_ylabel(\"Frequency (Hz)\")\n",
    "    ax1.set_title(\"Spectrogram (Visual Truth)\", fontsize=12)\n",
    "    ax1.grid(False)\n",
    "\n",
    "# --- BOTTOM PLOT: DETECTIONS ---\n",
    "# Plot Cat Voice\n",
    "ax2.plot(t_audio['frame_id'], t_audio['is_cat_voice'], \n",
    "         label='Cat (AST Model)', color='#FF8C00', linewidth=2, drawstyle='steps-post')\n",
    "\n",
    "# Plot Human Voice\n",
    "ax2.plot(t_audio['frame_id'], t_audio['is_human_voice'] + 0.05, \n",
    "         label='Human (AST Model)', color='#1E90FF', linestyle='--', linewidth=2, drawstyle='steps-post')\n",
    "\n",
    "ax2.set_ylabel(\"Detection\")\n",
    "ax2.set_xlabel(\"Frame ID\")\n",
    "ax2.set_title(\"AST Model Detections\", fontsize=12)\n",
    "ax2.set_yticks([0, 1])\n",
    "ax2.set_yticklabels(['Silence', 'Detected'])\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight detected regions\n",
    "cat_indices = t_audio[t_audio['is_cat_voice'] == 1]['frame_id']\n",
    "if not cat_indices.empty:\n",
    "    for frame in cat_indices:\n",
    "        ax2.axvspan(frame, frame + 1, color='orange', alpha=0.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
