{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1ab280-bf05-4f15-96e5-b3f1e7a34157",
   "metadata": {},
   "source": [
    "# Transformation Layer Demo - Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4fda1-5cc5-4e19-ae09-0962d26cb105",
   "metadata": {},
   "source": [
    "By: Asaf Brosh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a894deb-caef-4eff-bf67-13e1906ebbab",
   "metadata": {},
   "source": [
    "## Part 1: Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b030dd92-c65c-4be5-9a56-28bab33aecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation: we want to be able to classify a cat when the cat is stationary.\n",
    "\n",
    "# Raw Data Description: Cat isn't present in the frame for a few seconds, then the robot turns so the cat shows up.\n",
    "# Then the robot turns left and right, and for the last several seconds - stays steady.\n",
    "\n",
    "# Result: The cat is identified correctly after several seconds till the end of the video.\n",
    "# However, the model detecs changes in the cat movements even when stationary, probably as a result of absolute changes (that aren't intuitive).\n",
    "# The situation is slightly better with cat activity level, where we see mostly the correct, still classification.\n",
    "# Same goes with changes in distance, it works correctly when the robot is stationary, but overly classifies in movement.\n",
    "# Movement intensity and cat interaction coming from the IMU sensor worked correctly, with least intensity when stationary.\n",
    "\n",
    "# Next Steps: \n",
    "# 1. Which of the movement features should we keep?\n",
    "# 2. How to calibrate the features to classify more conservatively?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c524d8-f593-488b-bcf1-c3a4b9ec54b0",
   "metadata": {},
   "source": [
    "## Part 2: Robot Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8e8f45-9b96-46a2-90d4-c174df3fef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation: we want to be able to describe the robot's movements correctly.\n",
    "\n",
    "# Raw Data Description: Robot moves left and right, back and forth in bad light conditions.\n",
    "\n",
    "# Result: Cat detected correctly in all frames.\n",
    "# It detects the movement closer correctly, but when it comes to direction it chooses only one despite multiple frames.\n",
    "# The IMU feaures worked correctly\n",
    "\n",
    "# Next Steps: \n",
    "# 1. Which value should we print when the movement is both left and right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c198c-073e-40bc-a4fe-e2662fb823ba",
   "metadata": {},
   "source": [
    "## Part 3: Kafa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "490b1e2a-4846-4c75-ac39-dab7c80ca6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation: we want to be able to detect touch between the cat's paw and the IMU sensor.\n",
    "\n",
    "# Raw Data Description: Darab moves the arm, we can't tell whether or on each moment a Kafa took place.\n",
    "\n",
    "# Result: In both attempts, the cat interaction flag was on, probably even when it's just the arm moving.\n",
    "# The problem is, that we don't know when the Kafa took place, so isolating that moment and examine the data is impossible.\n",
    "\n",
    "# Next Steps: \n",
    "# 1. Redo that part, this time filming the robot. mimic a cat's touch.\n",
    "# 2. Learn how to differentiate a Kafa from arm movements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159e039-ea4f-435f-b409-bd71d58e814c",
   "metadata": {},
   "source": [
    "## Part 4: Cat No Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885e03fb-fd8a-4612-bf44-e27d44cd15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation: we want to be able to detect direction and transition of the cat off the frame.\n",
    "\n",
    "# Raw Data Description: Cat is stationary, then leaves off the right side of the frame.\n",
    "\n",
    "# Result: It detects the movement to the right correctly, but again overclassifies movements in direction and closeness.\n",
    "# Also, it assigns values such as \"still\" even when the cat detection flag is off.\n",
    "\n",
    "# Next Steps: \n",
    "# 1. Correct overclassification.\n",
    "# 2. If cat detection is off, other related values should be null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939205cb-d105-4828-9252-5555e7676a78",
   "metadata": {},
   "source": [
    "## Part 5: Mewo and Human Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011b2351-af75-40eb-9c53-c6e684aa1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation: we want to be able to detect both a mewo and a human voice.\n",
    "\n",
    "# Raw Data Description: Darab is speaking, then Asaf is mimicing a mewo sound, then a real mewo is barely heard.\n",
    "# Quality is poor so the mewo is hard to detect even for a human.\n",
    "\n",
    "# Result: It detects the human voice correctly, but ignores the mewo mimicing and the real mewo.\n",
    "\n",
    "# Next Steps: \n",
    "# 1. Improve sound quality and repeat with a recorded cat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
